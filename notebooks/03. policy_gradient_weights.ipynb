{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57847ba7-606b-4579-a802-a2574a1f3267",
   "metadata": {},
   "source": [
    "# Policy gradient weights\n",
    "\n",
    "In the previous notebook we ended with the following equation for estimating the gradient of the expected return for a certain policy $\\pi_\\theta$:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\pi_\\theta) = \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[\\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t) R(\\tau)]\n",
    "$$\n",
    "\n",
    "where $R(\\tau)$, the return of an episode, is defined is:\n",
    "\n",
    "$$\n",
    "R(\\tau) = \\sum_{t=0}^T r_t\n",
    "$$\n",
    "\n",
    "\n",
    "When thinking about this equation intuitively, it basically *scales* the probability of an action $a_t$ given a certain state $s_t$ with the return of the episode they belong to. If that episode was a 'good' one, i.e. a high return, the term will increase, further 'reinforcing' that action. If the return is bad, it will not be reinforced as much. Over time, this will make actions that lead to a high return more likely than actions that lead to a lower return. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b75ba9-dda1-4cc6-972c-5f65620c5c6c",
   "metadata": {},
   "source": [
    "However, this means that an action that occurred halfway through an episode, also incorporates rewards from timesteps that happened *before* that action. But how can an action be responsible for something that happened before that action was taken?\n",
    "\n",
    "Instead, we want actions to be reinforced based on rewards that happened *after* that action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02a6da-e84c-423f-9294-5d34e8512ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
