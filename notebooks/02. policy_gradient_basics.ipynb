{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794ae45a-75c6-4931-a3a2-c58960b0adf9",
   "metadata": {},
   "source": [
    "# Policy gradient basics\n",
    "\n",
    "This notebook aims to describe the basics of learning a policy based on gradients. We will go through the math as well as the code and implement a learning algorithm which we will run on a simple environment.\n",
    "This notebook is highly inspired by [SpinningUp from OpenAI](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html), but aims to bring the code and the math better together.\n",
    "\n",
    "#### Recap\n",
    "We have an environment in which the agent can act. At time $t$, the agent observes the state $s_t$, performs an action $a_t$, which yields a reward $r_t$ and the environment transitions to state $s_{t+1}$.\n",
    "\n",
    "Collecting a episode or trajectory $\\tau$ means acting in the environment until it is 'terminated' (task fails or succeeds) or until a prespecified limit, in which case the trajectory is 'truncated'.\n",
    "\n",
    "It is common to sum the rewards received in a episode. We call this the 'return' of the episode: $R(\\tau) = \\sum_{t=0}^T r_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f5dd8-6151-4bc9-8b40-dd639f6fa6b6",
   "metadata": {},
   "source": [
    "### Policy\n",
    "\n",
    "A policy is a function that maps an observation at time $t$ to an action *distribution*. A policy is often denoted with $\\pi$.\n",
    "\n",
    "With this we can note the probability of action $a_t$ given $s_t$ as: $\\pi(a_t | s_t)$.\n",
    "\n",
    "When learning a policy, it means the policy is parametrized, i.e. we need to learn the parameters of the function (in the case of neural networks these are its weights). We denote parameters as $\\theta$, and a parametrized policy as $\\pi_{\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6df48b3-388a-487c-ba2a-84e517e94104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "torch.manual_seed(13)\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41360c13-4b59-4195-9705-1fcb24507748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscretePolicy(nn.Module):\n",
    "    def __init__(self, observation_size, actions_size, layer_sizes=[32]):\n",
    "        super().__init__()\n",
    "\n",
    "        layer_sizes = [observation_size] + layer_sizes\n",
    "\n",
    "        layers = []\n",
    "        for layer_in, layer_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.append(nn.Linear(layer_in, layer_out))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(layer_sizes[-1], actions_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.output(self.net(x))\n",
    "        return logits\n",
    "\n",
    "    def get_action_distribution(self, observations):\n",
    "        return Categorical(logits=self(torch.as_tensor(observations, dtype=torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38282bf-73ee-47a5-a897-08b20d7e4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TimeLimit(gym.make('CartPole-v1', render_mode=\"rgb_array\"), max_episode_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4856ddc9-bd87-4819-a247-036160dcbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = DiscretePolicy(\n",
    "    observation_size=env.observation_space.shape[0],\n",
    "    actions_size=env.action_space.n,\n",
    "    layer_sizes=[32],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6ec48-8715-47ea-b2db-6fa1773bc64e",
   "metadata": {},
   "source": [
    "So, now we have a policy that takes as input an observation, and outputs so called *logits*. *logits* in this case will represent an *unnormalized action distribution*, i.e. the values of the probabilities before they are turned into actual probabilities.\n",
    "\n",
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fef4f8-6e8d-42ad-9d8b-be2b10029293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03647976,  0.03553025,  0.03110234, -0.02385536], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, _ = env.reset(seed=13)\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae82ed6-0506-453a-803d-8daf056d1cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4299, -0.0215])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = policy(torch.as_tensor(obs, dtype=torch.float32))\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a6264-51fc-44de-bfb9-ecb9fc38ca69",
   "metadata": {},
   "source": [
    "These two values stand for the two different actions we can take. We can put them into a (categorical, because our environment requires discrete actions) distribution and sample from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec811a8-aa96-40ad-ad7c-c2b4395541e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6110, 0.3890])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_distribution = Categorical(logits=logits)\n",
    "action_distribution.probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dcccf-7787-4858-98b3-9557d951a49c",
   "metadata": {},
   "source": [
    "This shows us that with our current policy $\\pi_\\theta$, and given observation $s_t$, we have a 61% probability of taking action 0 (pushing to the left) and 39% probability of taking action 1 (pushing to the right). Mathematically:\n",
    "\n",
    "$$\n",
    "\\pi_\\theta(a_0 | s_t) = 0.611\n",
    "$$\n",
    "$$\n",
    "\\pi_\\theta(a_1 | s_t) = 0.389\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e81c2c-eb3b-46d5-8357-7b026af4fe33",
   "metadata": {},
   "source": [
    "Finally, we can also easily calculate the log probability of a sample action for this policy (these will be needed during optimization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734f5621-c6f6-4c2f-9c97-56f8700a4e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: tensor(1)\n",
      "Logprob: tensor(-0.9441)\n"
     ]
    }
   ],
   "source": [
    "action = action_distribution.sample()\n",
    "print(\"Action:\", action)\n",
    "print(\"Logprob:\", action_distribution.log_prob(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aeef02-1488-42c5-ab62-a1822e303f15",
   "metadata": {},
   "source": [
    "### How to learn a policy?\n",
    "\n",
    "Up until now stuff looks pretty similar to the more well known supervised learning situation, in which we also create a neural network that outputs probabilities in the case of classification. However, the fundamental learning algorithm is quite different. In order to understand it, we will go through the mathematics of learning a policy.\n",
    "\n",
    "\n",
    "The first thing to realize is that we have no 'ground truth' policy. As opposed to supervised learning, we do not know what the output of the policy, the neural network, should be. As a result, we can only learn what is 'good' by acting in the environment, which gives us 'rewards' in return. In other words, we learn by gathering experience.\n",
    "\n",
    "The following derivation is taken quite literally from [SpinningUp OpenAI](https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html).\n",
    "\n",
    "Suppose we gather the experience for one episode. This means we get a set of observations, actions and rewards. If we look at the return of the episode, $R(\\tau)$, we get an overall idea of how 'well' the policy did.\n",
    "\n",
    "We can also state that the return is dependent on the policy $\\pi_\\theta$, and thus on the parameters of the policy. This means we can maximize this for this. Mathematically speaking, we want to maximize $J(\\pi)$:\n",
    "\n",
    "$$\n",
    "J(\\pi_\\theta) = \\int_{\\tau} P(\\tau | \\pi_\\theta) R(\\tau) = \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[R(\\tau)]\n",
    "$$\n",
    "\n",
    "In words: we want to maximize the expected return of an episode given a certain policy. The integral expresses this as for every episode that is possible, the probability of that episode happening given the policy times the return of that episode.\n",
    "\n",
    "Our key question actually now is: *How should we change the parameters $\\theta$ of $\\pi_\\theta$, in order to maximize the expected return?* This is similar to the supervised learning case where we want to change the parameters in order to match the expected output. And it turns out this step in the reinforcement learning case can also be expressed with gradients:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\pi_\\theta) = \\nabla_\\theta \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[R(\\tau)]\n",
    "$$\n",
    "\n",
    "Instead of the expectation we can write it as an integral:\n",
    "\n",
    "$$\n",
    " = \\nabla_\\theta \\int_{\\tau} P(\\tau | \\pi_\\theta) R(\\tau)\n",
    "$$\n",
    "\n",
    "Now, because the return of an episode is not dependent on the parameters (only on the environment), we can bring the gradient in:\n",
    "\n",
    "$$\n",
    " = \\int_{\\tau} \\nabla_\\theta P(\\tau | \\pi_\\theta) R(\\tau)\n",
    "$$\n",
    "\n",
    "This inner gradient of a probability $\\nabla_\\theta P(\\tau | \\pi)$ can be rewritten using the [log derivative trick](https://andrewcharlesjones.github.io/journal/log-derivative.html):\n",
    "\n",
    "$$\n",
    " = \\int_{\\tau} P(\\tau | \\pi_\\theta) \\nabla_\\theta \\log P(\\tau | \\pi_\\theta) R(\\tau)\n",
    "$$\n",
    "\n",
    "And we can bring this back to expectation form, which we can work with more easily:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\pi_\\theta) = \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[\\nabla_\\theta \\log P(\\tau | \\pi_\\theta)R(\\tau)]\n",
    "$$\n",
    "\n",
    "This is already much more applied, but we can rewrite it even more explicit if we work out $\\log P(\\tau | \\pi)$ some more. Without the log probability, we know the probability of an episode given its policy is given by:\n",
    "\n",
    "$$\n",
    "P(\\tau | \\pi_\\theta) = p_0(s_0) \\Pi_{t=0}^T p(s_{t+1} | s_t, a_t) \\pi_\\theta(a_t | s_t)\n",
    "$$\n",
    "\n",
    "In log form this becomes:\n",
    "\n",
    "$$\n",
    "\\log P(\\tau | \\pi_\\theta) = \\log p_0(s_0) + \\sum_{t=0}^T (\\log p(s_{t+1} | s_t, a_t) + \\log \\pi_\\theta(a_t | s_t))\n",
    "$$\n",
    "\n",
    "The gradient of this log probability, i.e. $\\nabla_\\theta \\log P(\\tau | \\pi_\\theta)$, allows us to remove the $\\log p_0(s_0)$ term and the $\\log p(s_{t+1} | s_t, a_t)$ term altogether. This is because these are based on the start conditions and on the environment, which do not depend on $\\theta$, thus:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\log P(\\tau | \\pi_\\theta) = \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t)\n",
    "$$\n",
    "\n",
    "\n",
    "Now, we can simplify our gradient from the previous steps further with this:\n",
    "$$\n",
    "\\nabla_\\theta J(\\pi_\\theta) = \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[\\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t) R(\\tau)]\n",
    "$$\n",
    "\n",
    "\n",
    "Finally! This is something we can code. Because it is an expectation, we can estimate this with the mean of a set of episodes.\n",
    "\n",
    "*Note: if you think the $R(\\tau)$ in the last equation is a bit weird then you are right, this will change later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9afd9-aca4-45f9-8b17-dcecacb8423f",
   "metadata": {},
   "source": [
    "First, we will implement a class that will help us store the gathered experience.\n",
    "\n",
    "*Reminder: with 'episode' I mean the same as 'trajectory'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83fce38-8a5d-4c17-8e44-c3eeeaaf6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceBuffer:\n",
    "    \"\"\" A class that stores experience. Can be used by storing episodes of data gathered by a specific policy\n",
    "    and provides helper functions for working with this experience during training. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.returns = []\n",
    "\n",
    "    def store_episode(self, observations, actions, rewards):\n",
    "        \"\"\" Stores all observations, actions and rewards for one episode. It also calculates the 'return' for this episode\n",
    "        and adds it as a list for all timesteps in the episode. \"\"\"\n",
    "\n",
    "        assert len(observations) == len(actions) == len(rewards), \"There should be an equal amount of observations, actions and rewards.\"\n",
    "\n",
    "        self.observations.extend(observations)\n",
    "        self.actions.extend(actions)\n",
    "        self.rewards.extend(rewards)\n",
    "\n",
    "        episode_return = sum(rewards)\n",
    "\n",
    "        # For every timestep in the episode we add the return for the complete episode.\n",
    "        # Doing it like this makes the calculations easier later on.\n",
    "        self.returns += [episode_return] * len(observations)\n",
    "\n",
    "    def get_as_tensors(self):\n",
    "        \"\"\" Returns all experience so far as tensors. \"\"\"\n",
    "        return (\n",
    "            torch.as_tensor(np.array(self.observations), dtype=torch.float32),\n",
    "            torch.as_tensor(np.array(self.actions), dtype=torch.float32),\n",
    "            torch.as_tensor(np.array(self.rewards), dtype=torch.float32),\n",
    "            torch.as_tensor(np.array(self.returns), dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\" Clears the buffer, making it ready for a new episode. \"\"\"\n",
    "\n",
    "        self.observations = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.returns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1357dbdf-cd75-41db-ba5c-1320d3f0678a",
   "metadata": {},
   "source": [
    "Next, we will implement a function that gathers data for an episode, and stores it in this buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab00583-70da-48c6-b340-5285435d7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_experience(env, policy, experience_buffer, seed=None):\n",
    "    \"\"\" Gathers experience for one episode and stores it in the buffer. \"\"\"\n",
    "    observations = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    observation, _ = env.reset(seed=seed)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        # During the collection of an episode, we do not need to store gradients.\n",
    "        with torch.no_grad():\n",
    "            action_distribution = policy.get_action_distribution(observation)\n",
    "\n",
    "        action = action_distribution.sample().item()\n",
    "        new_observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Store information about timestep t.\n",
    "        observations.append(observation)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            done = True\n",
    "\n",
    "        observation = new_observation\n",
    "\n",
    "    experience_buffer.store_episode(observations, actions, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83bf51d2-33f8-4dd2-936a-6dbf1b4e389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "buffer = ExperienceBuffer()\n",
    "policy = DiscretePolicy(\n",
    "    observation_size=env.observation_space.shape[0],\n",
    "    actions_size=env.action_space.n,\n",
    "    layer_sizes=[32],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2161f7a-98f7-4584-9bdd-6057d89e6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather_experience(env, policy, buffer, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51195a9f-6c37-4c82-aefe-41734e20e9ce",
   "metadata": {},
   "source": [
    "Okey, so now we've gathered the data for one episode. Let's look at what the buffer contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243a607f-40b7-4697-b657-54e9b8cc189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: torch.Size([23, 4])\n",
      "tensor([[-1.6973e-02, -9.4823e-03,  7.4738e-03,  6.3998e-04],\n",
      "        [-1.7163e-02, -2.0471e-01,  7.4866e-03,  2.9567e-01],\n",
      "        [-2.1257e-02, -9.6962e-03,  1.3400e-02,  5.3592e-03],\n",
      "        [-2.1451e-02,  1.8523e-01,  1.3507e-02, -2.8307e-01],\n",
      "        [-1.7746e-02,  3.8016e-01,  7.8459e-03, -5.7146e-01],\n",
      "        [-1.0143e-02,  1.8493e-01, -3.5833e-03, -2.7631e-01],\n",
      "        [-6.4446e-03,  3.8010e-01, -9.1096e-03, -5.7013e-01],\n",
      "        [ 1.1574e-03,  1.8511e-01, -2.0512e-02, -2.8033e-01],\n",
      "        [ 4.8595e-03, -9.7169e-03, -2.6119e-02,  5.8177e-03],\n",
      "        [ 4.6652e-03,  1.8577e-01, -2.6002e-02, -2.9499e-01],\n",
      "        [ 8.3806e-03,  3.8125e-01, -3.1902e-02, -5.9576e-01],\n",
      "        [ 1.6006e-02,  1.8659e-01, -4.3817e-02, -3.1329e-01],\n",
      "        [ 1.9737e-02,  3.8231e-01, -5.0083e-02, -6.1947e-01],\n",
      "        [ 2.7384e-02,  1.8792e-01, -6.2472e-02, -3.4297e-01],\n",
      "        [ 3.1142e-02,  3.8387e-01, -6.9332e-02, -6.5468e-01],\n",
      "        [ 3.8820e-02,  1.8978e-01, -8.2425e-02, -3.8461e-01],\n",
      "        [ 4.2615e-02,  3.8597e-01, -9.0118e-02, -7.0210e-01],\n",
      "        [ 5.0335e-02,  5.8222e-01, -1.0416e-01, -1.0217e+00],\n",
      "        [ 6.1979e-02,  3.8863e-01, -1.2459e-01, -7.6349e-01],\n",
      "        [ 6.9752e-02,  5.8523e-01, -1.3986e-01, -1.0926e+00],\n",
      "        [ 8.1456e-02,  3.9220e-01, -1.6172e-01, -8.4690e-01],\n",
      "        [ 8.9300e-02,  5.8911e-01, -1.7865e-01, -1.1858e+00],\n",
      "        [ 1.0108e-01,  7.8604e-01, -2.0237e-01, -1.5287e+00]])\n",
      "\n",
      "Actions: torch.Size([23])\n",
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1.])\n",
      "\n",
      "Rewards: torch.Size([23])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1.])\n",
      "\n",
      "Returns: torch.Size([23])\n",
      "tensor([23., 23., 23., 23., 23., 23., 23., 23., 23., 23., 23., 23., 23., 23.,\n",
      "        23., 23., 23., 23., 23., 23., 23., 23., 23.])\n"
     ]
    }
   ],
   "source": [
    "observations, actions, rewards, returns = buffer.get_as_tensors()\n",
    "\n",
    "print(\"Observations:\", observations.shape)\n",
    "print(observations)\n",
    "print(\"\\nActions:\", actions.shape)\n",
    "print(actions)\n",
    "print(\"\\nRewards:\", rewards.shape)\n",
    "print(rewards)\n",
    "print(\"\\nReturns:\", returns.shape)\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9726c9-7ff7-44ef-8741-73e63cc64054",
   "metadata": {},
   "source": [
    "Okey, so the episode took 23 timesteps. We have a 2D array with observations $s_t$ for every timestep. We also have the action $a_t$ and reward $r_t$ corresponding to that timestep and finally we have for every timestep the total return $R(\\tau)$ of the episode that observation/action/reward corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e81cdb-5602-4577-96b0-8fc2cca427e7",
   "metadata": {},
   "source": [
    "Now let's figure out how can calculate gradients for our policy based on this data.\n",
    "\n",
    "Remember from the previous section that our gradient is determined by the following equation:\n",
    "$$\n",
    "\\nabla_\\theta J(\\pi_\\theta) = \\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[\\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t | s_t) R(\\tau)]\n",
    "$$\n",
    "\n",
    "We also said that because this is an expectation, we can approximate it by sampling multiple trajectories and averaging them. In order to explore the idea, we will first do it for a single episode. The code for this formula looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea017d79-3411-4add-b8f4-ee5dbd1792a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-358.3914, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_return_estimate = torch.sum(policy.get_action_distribution(observations).log_prob(actions) * returns)\n",
    "expected_return_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605b217-1c68-412a-b128-d3985cc64635",
   "metadata": {},
   "source": [
    "This is our estimated expected return in reinforcement learning, but something *very* important to note:\n",
    "- This is the gradient of an objective we are trying to *maximize*, i.e. the expected return $\\underset{\\tau \\sim \\pi_\\theta}{\\mathbb{E}}[R(\\tau)]$. However, in supervised learning and in general when training neural networks, it is common to *minimize* an objective, like minimizing the mean squared error. Therefore, we must multiply this value by -1 in and then we can use torch optimizers as we usually do (minimizing the negative of a value is the same as maximizing that value). By convention we will then also call it loss\n",
    "\n",
    "Performing a policy update step with this measure can now be done as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11c14c3c-043b-48a7-b0da-2ee09295e6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bram/self/understanding-rl/.env/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(policy.parameters(), lr=1e-3)\n",
    "\n",
    "loss = -1 * expected_return_estimate\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cf265d-a7c1-420b-b55b-9efd1496a297",
   "metadata": {},
   "source": [
    "Great!\n",
    "\n",
    "Now, we estimated the expected return of the policy only using a single episode, but of course it is better to estimate it using multiple episodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212ee995-317f-4717-bffd-7ced9a2ba927",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.clear()\n",
    "\n",
    "# Gather experience for 1000 episodes.\n",
    "for _ in range(1000):\n",
    "    gather_experience(env, policy, buffer, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18ff36-73c7-472e-be38-a13c169d0784",
   "metadata": {},
   "source": [
    "Now, we can make a much better estimate for our expected return for this policy.\n",
    "\n",
    "We will make one change to calculating the expected return estimate, and that is by replacing `torch.sum` with `torch.mean`. We can do this because taking the average of episode gradients is the same as taking the average for all of them, and more importantly, it will not change the direction of the gradients, only the magnitude, which we can control anyway by setting the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff29082-a163-46d7-b4d0-9533de5d56be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timesteps in buffer: 25526\n"
     ]
    }
   ],
   "source": [
    "observations, actions, rewards, returns = buffer.get_as_tensors()\n",
    "print(\"Number of timesteps in buffer:\", observations.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27015ddc-8947-4565-8637-829bf0ea9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_return_estimate = torch.mean(policy.get_action_distribution(observations).log_prob(actions) * returns)\n",
    "loss = -1 * expected_return_estimate\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae67974-7fec-42f8-ac14-f077c59af3de",
   "metadata": {},
   "source": [
    "### Running an experiment\n",
    "\n",
    "Alright! That was all the theory for this notebook, now let's put it together and train an agent for multiple episodes.\n",
    "\n",
    "*Note: this cell is not seeded, so rerunning it will yield different results every time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4e7fd7b-4b8b-4872-86d0-91a61439384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_policy(env, n_epochs=100, n_episodes_per_epoch=100, learning_rate=1e-2, verbose=False):\n",
    "    \"\"\"\n",
    "    This function trains a policy for a given number of epochs, gathering a specified number of episodes\n",
    "    every epoch in order to estimate the expected return for the policy.\n",
    "\n",
    "    It returns a trained policy and the average return of all episodes for that epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    buffer = ExperienceBuffer()\n",
    "    policy = DiscretePolicy(\n",
    "        observation_size=env.observation_space.shape[0],\n",
    "        actions_size=env.action_space.n,\n",
    "        layer_sizes=[32],\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=learning_rate)\n",
    "\n",
    "    returns_per_epoch = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        buffer.clear()\n",
    "        for _ in range(n_episodes_per_epoch):\n",
    "            gather_experience(env, policy, buffer)\n",
    "    \n",
    "        observations, actions, rewards, returns = buffer.get_as_tensors()\n",
    "        loss = -1 * (policy.get_action_distribution(observations).log_prob(actions) * returns).mean()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        average_return = returns.detach().mean().item()\n",
    "        returns_per_epoch.append(average_return)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Finished epoch {epoch}. Average return over 100 episodes: {average_return}\")\n",
    "\n",
    "    return (\n",
    "        policy,\n",
    "        {\n",
    "            \"returns\": returns_per_epoch,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b3ddf-0343-4972-b0f5-ebc9e0e5065e",
   "metadata": {},
   "source": [
    "Let's run it once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa8e6f52-0883-4720-94a6-058fc3d09427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0. Average return over 100 episodes: 35.35093688964844\n",
      "Finished epoch 1. Average return over 100 episodes: 34.00365447998047\n",
      "Finished epoch 2. Average return over 100 episodes: 48.39229965209961\n",
      "Finished epoch 3. Average return over 100 episodes: 49.878597259521484\n",
      "Finished epoch 4. Average return over 100 episodes: 53.939598083496094\n",
      "Finished epoch 5. Average return over 100 episodes: 57.65279006958008\n",
      "Finished epoch 6. Average return over 100 episodes: 57.43192672729492\n",
      "Finished epoch 7. Average return over 100 episodes: 76.21390533447266\n",
      "Finished epoch 8. Average return over 100 episodes: 65.61418914794922\n",
      "Finished epoch 9. Average return over 100 episodes: 76.71944427490234\n",
      "Finished epoch 10. Average return over 100 episodes: 73.46785736083984\n",
      "Finished epoch 11. Average return over 100 episodes: 69.3333969116211\n",
      "Finished epoch 12. Average return over 100 episodes: 74.50746154785156\n",
      "Finished epoch 13. Average return over 100 episodes: 88.47579956054688\n",
      "Finished epoch 14. Average return over 100 episodes: 87.07266235351562\n"
     ]
    }
   ],
   "source": [
    "policy, train_info = train_policy(env, n_epochs=15, n_episodes_per_epoch=100, learning_rate=1e-2, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc67225-26bb-4c92-8178-8518eab370d5",
   "metadata": {},
   "source": [
    "Now let's run an experiment where we train a policy 10 times for 50 epochs. We record the average return per epoch. Then we plot the average of this line to get an idea of how the policies evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a30d97bd-3556-45ac-8416-f349815d74ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment 0\n",
      "Running experiment 1\n",
      "Running experiment 2\n",
      "Running experiment 3\n",
      "Running experiment 4\n",
      "Running experiment 5\n",
      "Running experiment 6\n",
      "Running experiment 7\n",
      "Running experiment 8\n",
      "Running experiment 9\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Running experiment {i}\")\n",
    "    policy, train_info = train_policy(env, n_epochs=50, n_episodes_per_epoch=100, learning_rate=1e-2, verbose=False)\n",
    "    results.append(train_info[\"returns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99be8c2b-0eac-440b-950f-a43c21257586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_collection(results: list[list[float]]):\n",
    "    \"\"\" Plots a list of experiment results. \"\"\"\n",
    "\n",
    "    data = np.array(results)\n",
    "    average_line = data.mean(axis=0)\n",
    "    standard_deviations = data.std(axis=0)\n",
    "\n",
    "    upper_bound = average_line + standard_deviations\n",
    "    lower_bound = average_line - standard_deviations\n",
    "\n",
    "    ax = sns.lineplot(average_line)\n",
    "    ax.fill_between(np.arange(len(average_line)), lower_bound, upper_bound, alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "885167d4-5b46-4a4f-9de1-c5972a958668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_line_collection(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec73853-65d9-4286-a397-504102296015",
   "metadata": {},
   "source": [
    "Very awesome. You can see how all agents learned over time. We can interpret the results as:\n",
    " - It seems that all agents learned to keep the pole up for 250 steps on average after 50 epochs, while in the beginning this was only 25 steps.\n",
    " - Note that when creating the environment, we limited the maximum number of steps to 300, so it is very close to 'nailing' the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd411d-b97c-48fa-bd92-0e5f2022f91c",
   "metadata": {},
   "source": [
    "### Evaluating an agent\n",
    "\n",
    "It might not be entirely fair to use the average return of the episode while gathering experience.\n",
    "While gathering experience, we *randomly sample* an action from the action distribution. However, when we want to know how well a policy works, we should actually see how it does when selecting *the most probable* action from the distribution during an episode.\n",
    "\n",
    "Let's train a policy and evaluate it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31bd7c20-efdc-4f1c-b754-a76c90cd80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy, train_info = train_policy(env, n_epochs=50, n_episodes_per_epoch=100, learning_rate=1e-2, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca0ad21c-7767-406a-9774-a5910339f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last average return: 238.4189453125\n"
     ]
    }
   ],
   "source": [
    "print(\"Last average return:\", train_info[\"returns\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4db12b3d-9805-421a-a459-a9c9c83a9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env, policy, n_episodes=100, render=False):\n",
    "    returns = []\n",
    "    for _ in range(n_episodes):\n",
    "        observation, _ = env.reset()\n",
    "        episode_return = 0\n",
    "\n",
    "        if render:\n",
    "            screen = plt.imshow(env.render())\n",
    "    \n",
    "        done = False\n",
    "        while not done:\n",
    "            if render:\n",
    "                screen.set_data(env.render())\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                action_distribution = policy.get_action_distribution(observation)\n",
    "\n",
    "            action = torch.argmax(action_distribution.probs).item()\n",
    "            observation, reward, terminated, truncated, _ = env.step(action)\n",
    "            episode_return += reward\n",
    "\n",
    "            if terminated or truncated:\n",
    "                done = True\n",
    "\n",
    "        returns.append(episode_return)\n",
    "\n",
    "    return np.mean(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a995e179-e93e-4ca4-ad37-1858a459fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297.69"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4f178-95c8-4c6e-a46c-adae7f8dac75",
   "metadata": {},
   "source": [
    "This means that on all 100 episodes the agent reached the maximum number of timesteps of the environment (rendering is extremely whack I'm sorry, does anyone know how to do this better?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b8b9088-472a-422c-a442-fe4e2ec7a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd387c75-4e31-49bf-9257-fd364899aade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_policy(env, policy, n_episodes=1, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d27b1-edab-41f2-8f88-e1b7da5aa10c",
   "metadata": {},
   "source": [
    "Very nice. It is a neural network that learned how to balance a pole."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
